{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, ZeroPadding2D, Add, Input, LeakyReLU, \\\n",
    "                                    UpSampling2D, Concatenate, Lambda\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.losses import binary_crossentropy, sparse_categorical_crossentropy\n",
    "from batch_norm import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnet_anchors = np.array([(10, 13), (16, 30), (33, 23), (30, 61), (62, 45),\n",
    "                         (59, 119), (116, 90), (156, 198), (373, 326)], np.float32) / 416\n",
    "\n",
    "mnet_anchor_masks = np.array([[6, 7, 8], [3, 4, 5], [0, 1, 2]])\n",
    "\n",
    "iou_threshold = 0.5\n",
    "\n",
    "score_threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcast_iou(box_1, box_2):\n",
    "    # box_1: (..., (x1, y1, x2, y2))\n",
    "    # box_2: (N, (x1, y1, x2, y2))\n",
    "\n",
    "    # broadcast boxes\n",
    "    box_1 = tf.expand_dims(box_1, -2)\n",
    "    box_2 = tf.expand_dims(box_2, 0)\n",
    "    # new_shape: (..., N, (x1, y1, x2, y2))\n",
    "    new_shape = tf.broadcast_dynamic_shape(tf.shape(box_1), tf.shape(box_2))\n",
    "    box_1 = tf.broadcast_to(box_1, new_shape)\n",
    "    box_2 = tf.broadcast_to(box_2, new_shape)\n",
    "\n",
    "    int_w = tf.maximum(tf.minimum(box_1[..., 2], box_2[..., 2]) -\n",
    "                       tf.maximum(box_1[..., 0], box_2[..., 0]), 0)\n",
    "    int_h = tf.maximum(tf.minimum(box_1[..., 3], box_2[..., 3]) -\n",
    "                       tf.maximum(box_1[..., 1], box_2[..., 1]), 0)\n",
    "    int_area = int_w * int_h\n",
    "    box_1_area = (box_1[..., 2] - box_1[..., 0]) * \\\n",
    "        (box_1[..., 3] - box_1[..., 1])\n",
    "    box_2_area = (box_2[..., 2] - box_2[..., 0]) * \\\n",
    "        (box_2[..., 3] - box_2[..., 1])\n",
    "    return int_area / (box_1_area + box_2_area - int_area)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same conv layer as Darknet\n",
    "def Conv(x, filters, size, strides=1, batch_norm=True):\n",
    "    if strides == 1:\n",
    "        padding = 'same'\n",
    "    else:\n",
    "        x = ZeroPadding2D(((1, 0), (1, 0)))(x)  # top left half-padding\n",
    "        padding = 'valid'\n",
    "        \n",
    "    x = Conv2D(filters=filters, kernel_size=size, strides=strides, padding=padding,\n",
    "               use_bias=not batch_norm, kernel_regularizer=l2(0.0005))(x)\n",
    "    if batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(alpha=0.1)(x)\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvRes(x, filters):\n",
    "    prev = x\n",
    "    x = Conv(x, filters=filters // 2, size=1)\n",
    "    x = Conv(x, filters=filters, size=3)  \n",
    "    x = Add()([prev, x])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvResBlock(x, filters, num_blocks):\n",
    "    x = Conv(x, filters, 3, strides=2)\n",
    "    \n",
    "    for i in range(num_blocks):\n",
    "        x = ConvRes(x, filters)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MNET(name=None):\n",
    "    x = inputs = Input([416, 416, 3])\n",
    "    \n",
    "    x = Conv(x, 32, 3)\n",
    "    \n",
    "    x = ConvResBlock(x, 64, 1)\n",
    "    x = ConvResBlock(x, 128, 2)\n",
    "    x = x_1 = ConvResBlock(x, 256, 4)\n",
    "    x = x_2 = ConvResBlock(x, 512, 4)\n",
    "    x = ConvResBlock(x, 1024, 2)\n",
    "    \n",
    "    return tf.keras.Model(inputs, (x_1, x_2, x), name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MNETConv(filters, name=None):\n",
    "    def mnet_conv(x_in):\n",
    "        if isinstance(x_in, tuple):\n",
    "            inputs = Input(x_in[0].shape[1:]), Input(x_in[1].shape[1:])\n",
    "            x, x_skip = inputs\n",
    "\n",
    "            # concat with skip connection\n",
    "            x = Conv(x, filters, 1)\n",
    "            x = UpSampling2D(2)(x)\n",
    "            x = Concatenate()([x, x_skip])\n",
    "        else:\n",
    "            x = inputs = Input(x_in.shape[1:])\n",
    "\n",
    "#       Same feature detector as YoloV3\n",
    "        x = Conv(x, filters, 1)\n",
    "        x = Conv(x, filters * 2, 3)\n",
    "        x = Conv(x, filters, 1)\n",
    "        x = Conv(x, filters * 2, 3)\n",
    "        x = Conv(x, filters, 1)\n",
    "        return Model(inputs, x, name=name)(x_in)\n",
    "    return mnet_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Createst the (size/32, size/32, anchors_size, classes_5) encoding (stolen from yolov3)\n",
    "def output(filters, anchors, classes, name=None):\n",
    "#   Final part the of the yolo feature detector\n",
    "    def mnet_output(x_in):\n",
    "        x = inputs = Input(x_in.shape[1:])\n",
    "        x = Conv(x, filters * 2, 3)\n",
    "        x = Conv(x, anchors * (classes + 5), 1, batch_norm=False)\n",
    "        x = Lambda(lambda x: tf.reshape(x, (-1, tf.shape(x)[1], tf.shape(x)[2], anchors, classes + 5)))(x)\n",
    "        return tf.keras.Model(inputs, x, name=name)(x_in)\n",
    "    return mnet_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea taken from the YoloV3 paper with sigmoids during BB \n",
    "def boxes(pred, anchors, classes):\n",
    "    grid_size = tf.shape(pred)[1]\n",
    "    \n",
    "    box_xy, box_wh, objectness, class_probs = tf.split(pred, (2, 2, 1, classes), axis=-1)\n",
    "    \n",
    "    box_xy = tf.sigmoid(box_xy)\n",
    "    objectness = tf.sigmoid(objectness)\n",
    "    class_probs = tf.sigmoid(class_probs)\n",
    "    pred_box = tf.concat((box_xy, box_wh), axis=-1)\n",
    "    \n",
    "#   Creates the grid of size (grid_size x grid_size)\n",
    "    grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
    "    grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)\n",
    "    \n",
    "    box_xy = (box_xy + tf.cast(grid, tf.float32)) / tf.cast(grid_size, tf.float32)\n",
    "    box_wh = tf.exp(box_wh) * anchors\n",
    "    \n",
    "    box_x1y1 = box_xy - box_wh / 2\n",
    "    box_x2y2 = box_xy + box_wh / 2\n",
    "    bbox = tf.concat([box_x1y1, box_x2y2], axis=-1)\n",
    "\n",
    "    return bbox, objectness, class_probs, pred_box\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms(outputs, anchors, masks, classes):\n",
    "#   Boxes, Conf, Type\n",
    "    b, c, t = [], [], []\n",
    "    \n",
    "    for o in outputs:\n",
    "        b.append(tf.reshape(o[0], (tf.shape(o[0])[0], -1, tf.shape(o[0])[-1])))\n",
    "        c.append(tf.reshape(o[1], (tf.shape(o[1])[0], -1, tf.shape(o[1])[-1])))\n",
    "        t.append(tf.reshape(o[2], (tf.shape(o[2])[0], -1, tf.shape(o[2])[-1])))\n",
    "        \n",
    "    bbox = tf.concat(b, axis=1)\n",
    "    confidence = tf.concat(c, axis=1)\n",
    "    class_probs = tf.concat(t, axis=1)\n",
    "    \n",
    "    scores = confidence * class_probs\n",
    "    \n",
    "    boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
    "        boxes=tf.reshape(bbox, (tf.shape(bbox)[0], -1, 1, 4)),\n",
    "        scores=tf.reshape(scores, (tf.shape(scores)[0], -1, tf.shape(scores)[-1])),\n",
    "        max_output_size_per_class=100,\n",
    "        max_total_size=100,\n",
    "        iou_threshold=iou_threshold,\n",
    "        score_threshold=score_threshold\n",
    "    )\n",
    "    \n",
    "    return boxes, scores, classes, valid_detections\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MNET_complete(size=None, channels=3, anchors=mnet_anchors, masks=mnet_anchor_masks, classes=80, training=False):\n",
    "    x = inputs = Input([size, size, channels])\n",
    "    \n",
    "    x_1, x_2, x = MNET(name=\"MNET\")(x)\n",
    "    \n",
    "    output_0 = output(512, len(masks[0]), classes, name='mnet_output_0')(x)\n",
    "\n",
    "    x = MNETConv(256, name='mnet_conv_1')((x, x_2))\n",
    "    output_1 = output(256, len(masks[1]), classes, name='mnet_output_1')(x)\n",
    "\n",
    "    x = MNETConv(128, name='mnet_conv_2')((x, x_1))\n",
    "    output_2 = output(128, len(masks[2]), classes, name='mnet_output_2')(x)\n",
    "    \n",
    "    if training:\n",
    "        return Model(inputs, (output_0, output_1, output_2), name='mnet')\n",
    "    \n",
    "    boxes_0 = Lambda(lambda x: boxes(x, anchors[masks[0]], classes), name='mnet_boxes_0')(output_0)\n",
    "    boxes_1 = Lambda(lambda x: boxes(x, anchors[masks[1]], classes), name='mnet_boxes_1')(output_1)\n",
    "    boxes_2 = Lambda(lambda x: boxes(x, anchors[masks[1]], classes), name='mnet_boxes_2')(output_2)\n",
    "\n",
    "    outputs = Lambda(lambda x: nms(x, anchors, masks, classes),\n",
    "                     name='mnet_nms')((boxes_0[:3], boxes_1[:3], boxes_2[:3]))\n",
    "\n",
    "    return Model(inputs, outputs, name='mnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completely stolen from Yolo paper and TF2 implementation\n",
    "def Loss(anchors, classes=80, ignore_thresh=0.5):\n",
    "    def loss(y_true, y_pred):\n",
    "        # 1. transform all pred outputs\n",
    "        # y_pred: (batch_size, grid, grid, anchors, (x, y, w, h, obj, ...cls))\n",
    "        pred_box, pred_obj, pred_class, pred_xywh = boxes(\n",
    "            y_pred, anchors, classes)\n",
    "        pred_xy = pred_xywh[..., 0:2]\n",
    "        pred_wh = pred_xywh[..., 2:4]\n",
    "\n",
    "        # 2. transform all true outputs\n",
    "        # y_true: (batch_size, grid, grid, anchors, (x1, y1, x2, y2, obj, cls))\n",
    "        true_box, true_obj, true_class_idx = tf.split(y_true, (4, 1, 1), axis=-1)\n",
    "        true_xy = (true_box[..., 0:2] + true_box[..., 2:4]) / 2\n",
    "        true_wh = true_box[..., 2:4] - true_box[..., 0:2]\n",
    "\n",
    "        # give higher weights to small boxes\n",
    "        box_loss_scale = 2 - true_wh[..., 0] * true_wh[..., 1]\n",
    "\n",
    "        # 3. inverting the pred box equations\n",
    "        grid_size = tf.shape(y_true)[1]\n",
    "        grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
    "        grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)\n",
    "        true_xy = true_xy * tf.cast(grid_size, tf.float32) - \\\n",
    "            tf.cast(grid, tf.float32)\n",
    "        true_wh = tf.math.log(true_wh / anchors)\n",
    "        true_wh = tf.where(tf.math.is_inf(true_wh), tf.zeros_like(true_wh), true_wh)\n",
    "\n",
    "        # 4. calculate all masks\n",
    "        obj_mask = tf.squeeze(true_obj, -1)\n",
    "        # ignore false positive when iou is over threshold\n",
    "        true_box_flat = tf.boolean_mask(true_box, tf.cast(obj_mask, tf.bool))\n",
    "        best_iou = tf.reduce_max(broadcast_iou(pred_box, true_box_flat), axis=-1)\n",
    "        ignore_mask = tf.cast(best_iou < ignore_thresh, tf.float32)\n",
    "\n",
    "        # 5. calculate all losses\n",
    "        xy_loss = obj_mask * box_loss_scale * tf.reduce_sum(tf.square(true_xy - pred_xy), axis=-1)\n",
    "        wh_loss = obj_mask * box_loss_scale * tf.reduce_sum(tf.square(true_wh - pred_wh), axis=-1)\n",
    "        obj_loss = binary_crossentropy(true_obj, pred_obj)\n",
    "        obj_loss = obj_mask * obj_loss + (1 - obj_mask) * ignore_mask * obj_loss\n",
    "        # TODO: use binary_crossentropy instead\n",
    "        \n",
    "        class_loss = obj_mask * sparse_categorical_crossentropy(true_class_idx, pred_class)\n",
    "\n",
    "        # 6. sum over (batch, gridx, gridy, anchors) => (batch, 1)\n",
    "        xy_loss = tf.reduce_sum(xy_loss, axis=(1, 2, 3))\n",
    "        wh_loss = tf.reduce_sum(wh_loss, axis=(1, 2, 3))\n",
    "        obj_loss = tf.reduce_sum(obj_loss, axis=(1, 2, 3))\n",
    "        class_loss = tf.reduce_sum(class_loss, axis=(1, 2, 3))\n",
    "\n",
    "        return xy_loss + wh_loss + obj_loss + class_loss\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
