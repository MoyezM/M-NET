{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, ZeroPadding2D, Add, Input, LeakyReLU, \\\n",
    "                                    UpSampling2D, Concatenate, Lambda\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.losses import binary_crossentropy, sparse_categorical_crossentropy\n",
    "from batch_norm import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_anchors = np.array([(10, 13), (16, 30), (33, 23), (30, 61), (62, 45),\n",
    "                         (59, 119), (116, 90), (156, 198), (373, 326)], np.float32) / 416\n",
    "\n",
    "yolo_anchor_masks = np.array([[6, 7, 8], [3, 4, 5], [0, 1, 2]])\n",
    "\n",
    "iou_threshold = 0.5\n",
    "\n",
    "score_threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same conv layer as Darknet\n",
    "def Conv(x, filters, size, strides=1, batch_norm=True):\n",
    "    if strides == 1:\n",
    "        padding = 'same'\n",
    "    else:\n",
    "        x = ZeroPadding2D(((1, 0), (1, 0)))(x)  # top left half-padding\n",
    "        padding = 'valid'\n",
    "        \n",
    "    x = Conv2D(filters=filters, kernel_size=size, strides=strides, padding=padding,\n",
    "               use_bias=not batch_norm, kernel_regularizer=l2(0.0005))(x)\n",
    "    if batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(alpha=0.1)(x)\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvRes(x, filters):\n",
    "    prev = x\n",
    "    x = Conv(x, filters=filters // 2, size=1)\n",
    "    x = Conv(x, filters=filters, size=3)  \n",
    "    x = Add()([prev, x])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvResBlock(x, filters, num_blocks):\n",
    "    x = Conv(x, filters, 3, strides=2)\n",
    "    \n",
    "    for i in range(num_blocks):\n",
    "        x = ConvRes(x, filters)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MNET(name=None):\n",
    "    x = inputs = Input([416, 416, 3])\n",
    "    \n",
    "    x = Conv(x, 32, 3)\n",
    "    \n",
    "    x = ConvResBlock(x, 64, 1)\n",
    "    x = ConvResBlock(x, 128, 2)\n",
    "    x = x_1 = ConvResBlock(x, 256, 4)\n",
    "    x = x_2 = ConvResBlock(x, 512, 4)\n",
    "    x = ConvResBlock(x, 1024, 2)\n",
    "    \n",
    "    return tf.keras.Model(inputs, (x_1, x_2, x), name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MNETConv(filters, name=None):\n",
    "    def mnet_conv(x_in):\n",
    "        if isinstance(x_in, tuple):\n",
    "            inputs = Input(x_in[0].shape[1:]), Input(x_in[1].shape[1:])\n",
    "            x, x_skip = inputs\n",
    "\n",
    "            # concat with skip connection\n",
    "            x = Conv(x, filters, 1)\n",
    "            x = UpSampling2D(2)(x)\n",
    "            x = Concatenate()([x, x_skip])\n",
    "        else:\n",
    "            x = inputs = Input(x_in.shape[1:])\n",
    "\n",
    "#       Same feature detector as YoloV3\n",
    "        x = Conv(x, filters, 1)\n",
    "        x = Conv(x, filters * 2, 3)\n",
    "        x = Conv(x, filters, 1)\n",
    "        x = Conv(x, filters * 2, 3)\n",
    "        x = Conv(x, filters, 1)\n",
    "        return Model(inputs, x, name=name)(x_in)\n",
    "    return mnet_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Createst the (size/32, size/32, anchors_size, classes_5) encoding (stolen from yolov3)\n",
    "def output(filters, anchors, classes, name=None):\n",
    "#   Final part the of the yolo feature detector\n",
    "    def mnet_output(x_in):\n",
    "        x = inputs = Input(x_in.shape[1:])\n",
    "        x = Conv(x, filters * 2, 3)\n",
    "        x = Conv(x, anchors * (classes + 5), 1, batch_norm=False)\n",
    "        x = Lambda(lambda x: tf.reshape(x, (-1, tf.shape(x)[1], tf.shape(x)[2], anchors, classes + 5)))(x)\n",
    "        return tf.keras.Model(inputs, x, name=name)(x_in)\n",
    "    return mnet_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea taken from the YoloV3 paper with sigmoids during BB \n",
    "def boxes(pred, anchors, classes):\n",
    "    grid_size = tf.shape(pred)[1]\n",
    "    \n",
    "    box_xy, box_wh, objectness, class_probs = tf.split(pred, (2, 2, 1, classes))\n",
    "    \n",
    "    box_xy = tf.sigmoid(box_xy)\n",
    "    objectness = tf.sigmoid(objectness)\n",
    "    class_probs = tf.sigmoid(class_probs)\n",
    "    pred_box = tf.concat((box_xy, box_wh), axis=-1)\n",
    "    \n",
    "#   Creates the grid of size (grid_size x grid_size)\n",
    "    grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
    "    grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)\n",
    "    \n",
    "    box_xy = (box_xy + tf.cast(grid, tf.float32)) / tf.cast(grid_sizem, tf.float32)\n",
    "    box_wh = tf.exp(box_wh) * anchors\n",
    "    \n",
    "    box_x1y1 = box_xy - box_wh / 2\n",
    "    box_x2y2 = box_xy + box_wh / 2\n",
    "    bbox = tf.concat([box_x1y1, box_x2y2], axis=-1)\n",
    "\n",
    "    return bbox, objectness, class_probs, pred_box\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms(outputs, anchors, masks, classes):\n",
    "#   Boxes, Conf, Type\n",
    "    b, c, t = [], [], []\n",
    "    \n",
    "    for o in outputs:\n",
    "        b.append(tf.reshape(o[0], (tf.shape(o[0])[0], -1, tf.shape(o[0])[-1])))\n",
    "        c.append(tf.reshape(o[1], (tf.shape(o[1])[0], -1, tf.shape(o[1])[-1])))\n",
    "        t.append(tf.reshape(o[2], (tf.shape(o[2])[0], -1, tf.shape(o[2])[-1])))\n",
    "        \n",
    "    bbox = tf.concat(b, axis=1)\n",
    "    confidence = tf.concat(c, axis=1)\n",
    "    class_probs = tf.concat(t, axis=1)\n",
    "    \n",
    "    scores = confidence * class_probs\n",
    "    \n",
    "    boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
    "        boxes=tf.reshape(bbox, (tf.shape(bbox)[0], -1, 1, 4)),\n",
    "        scores=tf.reshape(scores, (tf.shape(scores)[0], -1, tf.shape(scores)[-1])),\n",
    "        max_output_size_per_class=100,\n",
    "        max_total_size=100,\n",
    "        iou_threshold=iou_threshold,\n",
    "        score_threshold=score_threshold\n",
    "    )\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
